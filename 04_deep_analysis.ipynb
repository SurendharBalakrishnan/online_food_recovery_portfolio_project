{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuickBite Express - Deep Analysis (Part 2)\n",
    "## Sprint 2: Q4, Q5, Q6, Q7, Q9, Q10\n",
    "\n",
    "**Questions Covered:**\n",
    "- **Q4:** Cancellation rate trend pre-crisis vs crisis, most affected cities\n",
    "- **Q5:** Delivery SLA compliance across phases\n",
    "- **Q6:** Ratings fluctuation month-by-month\n",
    "- **Q7:** Negative keyword frequency in crisis reviews (Word Cloud)\n",
    "- **Q9:** Loyalty impact \u2014 churned loyal customers\n",
    "- **Q10:** High-value customer decline patterns\n",
    "\n",
    "**Input:** Cleaned datasets from `output/02_cleaned_data/`\n",
    "**Output:** Charts + insights to `output/04_deep_analysis/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 0. Setup & Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport seaborn as sns\nimport os\nfrom datetime import datetime\nfrom collections import Counter\nfrom matplotlib.patches import Patch\n\nCLEAN_DIR = \"output/02_cleaned_data/\"\nOUTPUT_DIR = \"output/04_deep_analysis/\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nNAVY = \"#1A2744\"; TEAL = \"#0D8A8A\"; ORANGE = \"#E8743B\"; SOFT_BLUE = \"#5B9BD5\"\nGRAY = \"#888888\"; RED = \"#D94F4F\"; GREEN = \"#2ECC71\"; PURPLE = \"#9B59B6\"\nLIGHT_ORANGE = \"#FFF3E0\"; LIGHT_RED = \"#FFEBEE\"\nMONTH_LABELS = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep']\n\nplt.rcParams.update({\n    'figure.figsize': (14, 6), 'figure.facecolor': 'white', 'axes.facecolor': 'white',\n    'font.family': 'sans-serif', 'font.size': 11, 'axes.titlesize': 16,\n    'axes.titleweight': 'bold', 'axes.labelsize': 12, 'axes.grid': True,\n    'grid.alpha': 0.3, 'grid.color': '#CCCCCC',\n})\nprint(\"\u2705 Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\ud83d\udcc2 Loading cleaned datasets...\")\nfact_orders = pd.read_csv(f\"{CLEAN_DIR}fact_orders_clean.csv\", parse_dates=['order_timestamp'])\nfact_order_items = pd.read_csv(f\"{CLEAN_DIR}fact_order_items_clean.csv\")\nfact_ratings = pd.read_csv(f\"{CLEAN_DIR}fact_ratings_clean.csv\")\nfact_delivery = pd.read_csv(f\"{CLEAN_DIR}fact_delivery_performance_clean.csv\")\ndim_customer = pd.read_csv(f\"{CLEAN_DIR}dim_customer_clean.csv\")\ndim_restaurant = pd.read_csv(f\"{CLEAN_DIR}dim_restaurant_clean.csv\")\ndim_delivery_partner = pd.read_csv(f\"{CLEAN_DIR}dim_delivery_partner_clean.csv\")\ndim_menu_item = pd.read_csv(f\"{CLEAN_DIR}dim_menu_item_clean.csv\")\n\nif 'phase' not in fact_orders.columns:\n    fact_orders['phase'] = fact_orders['order_timestamp'].apply(\n        lambda x: 'Pre-Crisis' if x < pd.Timestamp('2025-06-01') else 'Crisis')\nif 'order_month' not in fact_orders.columns:\n    fact_orders['order_month'] = fact_orders['order_timestamp'].dt.to_period('M').astype(str)\n\nprint(\"\u2705 All datasets loaded\")\nprint(f\"   Orders: {len(fact_orders):,} | Ratings: {len(fact_ratings):,} | Delivery: {len(fact_delivery):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Q4: Cancellation Rate Trend & Most Affected Cities\n\n> **Question:** What is the cancellation rate trend pre-crisis vs crisis, and which cities are most affected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\nprint(\"Q4: CANCELLATION RATE ANALYSIS\")\nprint(\"=\" * 70)\n\ncancel_monthly = fact_orders.groupby('order_month').agg(\n    total_orders=('order_id', 'count'),\n    cancelled=('is_cancelled', lambda x: (x == 'Y').sum())\n).reset_index()\ncancel_monthly['cancel_rate'] = (cancel_monthly['cancelled'] / cancel_monthly['total_orders'] * 100).round(2)\ncancel_monthly['phase'] = cancel_monthly['order_month'].apply(lambda x: 'Pre-Crisis' if x <= '2025-05' else 'Crisis')\n\nprint(\"\\n\ud83d\udcca Monthly Cancellation Rates:\")\nprint(cancel_monthly[['order_month', 'total_orders', 'cancelled', 'cancel_rate', 'phase']].to_string(index=False))\n\npre_rate = fact_orders[fact_orders['phase'] == 'Pre-Crisis']['is_cancelled'].apply(lambda x: x == 'Y').mean() * 100\ncrisis_rate = fact_orders[fact_orders['phase'] == 'Crisis']['is_cancelled'].apply(lambda x: x == 'Y').mean() * 100\nprint(f\"\\n\ud83d\udccb KEY METRICS:\")\nprint(f\"   Pre-Crisis Cancel Rate:  {pre_rate:.2f}%\")\nprint(f\"   Crisis Cancel Rate:      {crisis_rate:.2f}%\")\nprint(f\"   \ud83d\udd34 Rate Increase:        {crisis_rate - pre_rate:.2f} pp (~{((crisis_rate/pre_rate)-1)*100:.0f}% increase)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# City-wise cancellation\norders_city = fact_orders.merge(dim_restaurant[['restaurant_id', 'city']], on='restaurant_id', how='left')\ncity_cancel = orders_city.groupby(['city', 'phase']).agg(\n    total=('order_id', 'count'), cancelled=('is_cancelled', lambda x: (x == 'Y').sum())\n).reset_index()\ncity_cancel['cancel_rate'] = (city_cancel['cancelled'] / city_cancel['total'] * 100).round(2)\ncity_cancel_pivot = city_cancel.pivot(index='city', columns='phase', values='cancel_rate').reset_index()\ncity_cancel_pivot['rate_increase'] = (city_cancel_pivot['Crisis'] - city_cancel_pivot['Pre-Crisis']).round(2)\ncity_cancel_pivot = city_cancel_pivot.sort_values('Crisis', ascending=False)\nprint(\"\ud83d\udcca City-wise Cancellation Rates:\")\nprint(city_cancel_pivot.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHART Q4a: Monthly Cancellation Rate Trend\nfig, ax = plt.subplots(figsize=(14, 6))\nmonths = cancel_monthly['order_month'].values\nrates = cancel_monthly['cancel_rate'].values\n\nax.plot(months, rates, color=NAVY, linewidth=2, marker='o', markersize=8, zorder=3)\nfor i, (m, r) in enumerate(zip(months, rates)):\n    color = NAVY if m <= '2025-05' else RED\n    ax.plot(m, r, 'o', color=color, markersize=10, zorder=4)\n    ax.annotate(f'{r:.1f}%', (m, r), textcoords='offset points', xytext=(0, 14),\n                ha='center', fontsize=10, fontweight='bold', color=color)\n\nax.axvspan(4.5, 8.5, alpha=0.08, color=RED, zorder=0)\nax.axvline(x=4.5, color=RED, linestyle='--', alpha=0.5, linewidth=1.5)\nax.axhline(y=pre_rate, xmin=0, xmax=0.56, color=NAVY, linestyle=':', alpha=0.4)\nax.axhline(y=crisis_rate, xmin=0.56, xmax=1, color=RED, linestyle=':', alpha=0.4)\n\nax.annotate(f'Nearly doubled\\n({pre_rate:.1f}% \u2192 {crisis_rate:.1f}%)', xy=(5, rates[5]),\n            xytext=(3, 10), fontsize=11, fontweight='bold', color=RED,\n            arrowprops=dict(arrowstyle='->', color=RED, lw=2),\n            bbox=dict(boxstyle='round,pad=0.3', facecolor=LIGHT_RED, edgecolor=RED, alpha=0.9))\n\nax.set_title('Q4: Monthly Cancellation Rate', fontsize=18, fontweight='bold', color=NAVY, pad=20)\nax.set_xlabel('Month (2025)', fontsize=12, color=GRAY)\nax.set_ylabel('Cancellation Rate (%)', fontsize=12, color=GRAY)\nax.set_xticklabels(MONTH_LABELS)\nax.set_ylim(0, max(rates) * 1.3)\nax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\nplt.tight_layout()\nplt.savefig(f'{OUTPUT_DIR}Q4a_cancellation_trend.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"\u2705 Chart saved: Q4a_cancellation_trend.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHART Q4b: City-wise Heatmap\norders_city['order_month'] = orders_city['order_timestamp'].dt.to_period('M').astype(str)\ncity_month_cancel = orders_city.groupby(['city', 'order_month']).agg(\n    total=('order_id', 'count'), cancelled=('is_cancelled', lambda x: (x == 'Y').sum())\n).reset_index()\ncity_month_cancel['rate'] = (city_month_cancel['cancelled'] / city_month_cancel['total'] * 100).round(1)\nheatmap_data = city_month_cancel.pivot(index='city', columns='order_month', values='rate')\n\nfig, ax = plt.subplots(figsize=(14, 6))\nsns.heatmap(heatmap_data, annot=True, fmt='.1f', cmap='YlOrRd', ax=ax,\n            cbar_kws={'label': 'Cancel Rate %', 'shrink': 0.8}, linewidths=0.5, linecolor='white')\nax.set_title('Q4b: Cancellation Heatmap by City & Month', fontsize=16, fontweight='bold', color=NAVY, pad=15)\nax.set_xlabel('Month', fontsize=11, color=GRAY); ax.set_ylabel('')\nax.set_xticklabels(MONTH_LABELS, rotation=45)\nplt.tight_layout()\nplt.savefig(f'{OUTPUT_DIR}Q4b_city_cancellation_heatmap.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"\u2705 Chart saved: Q4b_city_cancellation_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 Insight Summary\n\n",
    "**Finding:** Cancellation rate nearly **doubled** from ~6.1% (pre-crisis) to ~11.9% (crisis).\n\n",
    "- Cancellations spiked immediately in June and stayed elevated through September.\n",
    "- **Ahmedabad (13.0%)** and **Mumbai (12.4%)** had the highest crisis cancellation rates.\n",
    "- The sustained rate suggests ongoing operational issues, not a one-time spike."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Q5: Delivery SLA Compliance Across Phases\n\n> **Question:** Measure average delivery time across phases. Did SLA compliance worsen significantly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\nprint(\"Q5: DELIVERY SLA COMPLIANCE\")\nprint(\"=\" * 70)\n\norders_del = fact_orders.merge(fact_delivery, on='order_id', how='left')\norders_del['sla_breach'] = (orders_del['actual_delivery_time_mins'] > orders_del['expected_delivery_time_mins']).astype(int)\norders_del['delay_mins'] = orders_del['actual_delivery_time_mins'] - orders_del['expected_delivery_time_mins']\n\nsla_monthly = orders_del.groupby('order_month').agg(\n    avg_actual=('actual_delivery_time_mins', 'mean'), avg_expected=('expected_delivery_time_mins', 'mean'),\n    avg_delay=('delay_mins', 'mean'), breach_count=('sla_breach', 'sum'), total=('order_id', 'count')\n).reset_index()\nsla_monthly['breach_rate'] = (sla_monthly['breach_count'] / sla_monthly['total'] * 100).round(2)\n\nprint(\"\\n\ud83d\udcca Monthly SLA Metrics:\")\nprint(sla_monthly[['order_month', 'avg_actual', 'avg_expected', 'avg_delay', 'breach_rate']].round(1).to_string(index=False))\n\nfor phase in ['Pre-Crisis', 'Crisis']:\n    df = orders_del[orders_del['phase'] == phase]\n    print(f\"\\n\ud83d\udccb {phase}: Avg Actual={df['actual_delivery_time_mins'].mean():.1f}min, \"\n          f\"Avg Expected={df['expected_delivery_time_mins'].mean():.1f}min, \"\n          f\"SLA Breach={df['sla_breach'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHART Q5: Dual-Axis Delivery Time + SLA Breach Rate\nfig, ax1 = plt.subplots(figsize=(14, 7))\nmonths = sla_monthly['order_month'].values\n\nax1.plot(months, sla_monthly['avg_actual'], color=RED, linewidth=2.5, marker='s', markersize=8, label='Actual Time', zorder=3)\nax1.plot(months, sla_monthly['avg_expected'], color=TEAL, linewidth=2.5, marker='o', markersize=8, label='Expected Time', zorder=3)\nax1.fill_between(months, sla_monthly['avg_expected'], sla_monthly['avg_actual'], alpha=0.15, color=RED, label='Delivery Gap')\n\nax2 = ax1.twinx()\nax2.bar(months, sla_monthly['breach_rate'], alpha=0.25, color=ORANGE, width=0.4, label='SLA Breach Rate', zorder=1)\nax2.set_ylabel('SLA Breach Rate (%)', fontsize=12, color=ORANGE)\nax2.set_ylim(0, 100)\n\nax1.axvspan(4.5, 8.5, alpha=0.05, color=ORANGE, zorder=0)\nax1.axvline(x=4.5, color=ORANGE, linestyle='--', alpha=0.5)\n\nax1.annotate('39.5 \u2192 60.1 mins (+52%)\\nBreach: 56% \u2192 88%', xy=(5, sla_monthly.iloc[5]['avg_actual']),\n             xytext=(2, 55), fontsize=11, fontweight='bold', color=RED,\n             arrowprops=dict(arrowstyle='->', color=RED, lw=2),\n             bbox=dict(boxstyle='round,pad=0.3', facecolor=LIGHT_RED, edgecolor=RED, alpha=0.9))\n\nax1.set_title('Q5: Delivery SLA Compliance', fontsize=18, fontweight='bold', color=NAVY, pad=20)\nax1.set_xlabel('Month (2025)', fontsize=12, color=GRAY)\nax1.set_ylabel('Delivery Time (mins)', fontsize=12, color=NAVY)\nax1.set_xticklabels(MONTH_LABELS)\nax1.spines['top'].set_visible(False)\nlines1, labels1 = ax1.get_legend_handles_labels()\nlines2, labels2 = ax2.get_legend_handles_labels()\nax1.legend(lines1 + lines2, labels1 + labels2, loc='center left', fontsize=10)\nplt.tight_layout()\nplt.savefig(f'{OUTPUT_DIR}Q5_sla_compliance.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"\u2705 Chart saved: Q5_sla_compliance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5 Insight Summary\n\n",
    "**Finding:** SLA breach rate jumped from **56% to 88%**. Actual delivery time increased from **39.5 to 60.1 minutes (+52%)**.\n\n",
    "- The monsoon delivery outage devastated operations.\n",
    "- Even pre-crisis breach rate (~56%) was concerning \u2014 now catastrophic at 88%.\n",
    "- Fixing delivery infrastructure is critical for recovery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Q6: Ratings Fluctuation Month-by-Month\n\n> **Question:** Track average customer rating month-by-month. Which months saw the sharpest drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\nprint(\"Q6: RATINGS FLUCTUATION\")\nprint(\"=\" * 70)\n\nratings_monthly = fact_ratings.merge(fact_orders[['order_id', 'order_month', 'phase']], on='order_id', how='left')\nmonthly_rating = ratings_monthly.groupby('order_month').agg(\n    avg_rating=('rating', 'mean'), avg_sentiment=('sentiment_score', 'mean'),\n    review_count=('order_id', 'count')\n).reset_index()\nmonthly_rating['mom_change'] = monthly_rating['avg_rating'].diff().round(3)\n\nprint(\"\\n\ud83d\udcca Monthly Rating Trends:\")\nprint(monthly_rating[['order_month', 'avg_rating', 'avg_sentiment', 'review_count', 'mom_change']].round(2).to_string(index=False))\n\nsharpest_idx = monthly_rating['mom_change'].idxmin()\nsharpest = monthly_rating.loc[sharpest_idx]\nprint(f\"\\n\ud83d\udd34 Sharpest Drop: {sharpest['order_month']} (change: {sharpest['mom_change']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHART Q6: Monthly Avg Rating + Sentiment\nfig, ax1 = plt.subplots(figsize=(14, 7))\nmonths = monthly_rating['order_month'].values\nratings_vals = monthly_rating['avg_rating'].values\nsentiment_vals = monthly_rating['avg_sentiment'].values\n\nax1.plot(months, ratings_vals, color=TEAL, linewidth=3, marker='o', markersize=10, label='Avg Rating', zorder=3)\nfor i, (m, r) in enumerate(zip(months, ratings_vals)):\n    color = TEAL if m <= '2025-05' else RED\n    ax1.annotate(f'{r:.2f}', (m, r), textcoords='offset points', xytext=(0, 14),\n                 ha='center', fontsize=10, fontweight='bold', color=color)\n\nax2 = ax1.twinx()\nax2.bar(months, sentiment_vals, alpha=0.3, width=0.5,\n        color=[TEAL if s >= 0 else RED for s in sentiment_vals], label='Sentiment', zorder=1)\nax2.set_ylabel('Sentiment Score', fontsize=12, color=GRAY)\nax2.axhline(y=0, color=GRAY, linestyle='-', linewidth=0.5)\nax2.set_ylim(-0.5, 1.0)\n\nax1.axvspan(4.5, 8.5, alpha=0.05, color=RED, zorder=0)\nax1.axvline(x=4.5, color=RED, linestyle='--', alpha=0.5)\n\nax1.annotate(f'Sharpest drop: {sharpest[\"order_month\"]}\\n({sharpest[\"mom_change\"]:+.2f})',\n             xy=(sharpest_idx, ratings_vals[sharpest_idx]),\n             xytext=(sharpest_idx - 2, ratings_vals[sharpest_idx] + 0.6),\n             fontsize=11, fontweight='bold', color=RED,\n             arrowprops=dict(arrowstyle='->', color=RED, lw=2),\n             bbox=dict(boxstyle='round,pad=0.3', facecolor=LIGHT_RED, edgecolor=RED, alpha=0.9))\n\nax1.set_title('Q6: Monthly Rating & Sentiment Trend', fontsize=18, fontweight='bold', color=NAVY, pad=20)\nax1.set_xlabel('Month (2025)', fontsize=12, color=GRAY)\nax1.set_ylabel('Average Rating (1-5)', fontsize=12, color=NAVY)\nax1.set_xticklabels(MONTH_LABELS); ax1.set_ylim(1.5, 5.5)\nax1.spines['top'].set_visible(False)\nlines1, labels1 = ax1.get_legend_handles_labels()\nlines2, labels2 = ax2.get_legend_handles_labels()\nax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right', fontsize=10)\nplt.tight_layout()\nplt.savefig(f'{OUTPUT_DIR}Q6_rating_trend.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"\u2705 Chart saved: Q6_rating_trend.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6 Insight Summary\n\n",
    "**Finding:** Average rating crashed from **~4.5 stars to ~2.5 stars** \u2014 a 2-star drop. Sentiment went from +0.75 to -0.25.\n\n",
    "- Ratings continued declining through Sep (2.31) \u2014 problem is worsening.\n",
    "- Distribution completely flipped from majority 4-5 stars to majority 1-2 stars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Q7: Negative Keyword Frequency \u2014 Word Cloud\n\n> **Question:** During the crisis period, identify the most frequently occurring negative keywords in customer review texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\nprint(\"Q7: NEGATIVE KEYWORD ANALYSIS\")\nprint(\"=\" * 70)\n\ncrisis_reviews = ratings_monthly[ratings_monthly['phase'] == 'Crisis']\nneg_reviews = crisis_reviews[crisis_reviews['sentiment_score'] < 0]\nprint(f\"\\nCrisis Reviews: {len(crisis_reviews):,} | Negative: {len(neg_reviews):,} ({len(neg_reviews)/len(crisis_reviews)*100:.1f}%)\")\n\nstopwords = {'the','is','was','a','an','and','or','but','in','on','at','to','for','of','with',\n             'it','not','this','that','i','my','me','very','than','so','too','be','been','being',\n             'have','has','had','do','does','did','will','would','could','should','no'}\n\nwords = []\nfor text in neg_reviews['review_text'].dropna():\n    for word in text.lower().split():\n        w = word.strip('.,!?;:')\n        if w and w not in stopwords and len(w) > 2:\n            words.append(w)\n\nword_freq = Counter(words)\nprint(f\"\\n\ud83d\udd1d Top 20 Negative Keywords:\")\nfor word, count in word_freq.most_common(20):\n    bar = '\u2588' * int(count / 100)\n    print(f\"   {word:<20} {count:>5} {bar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHART Q7a: Word Cloud\ntry:\n    from wordcloud import WordCloud\n    wc = WordCloud(width=1200, height=600, background_color='white', colormap='RdYlBu_r',\n                   max_words=80, max_font_size=120, min_font_size=12, prefer_horizontal=0.7, relative_scaling=0.5)\n    wc.generate_from_frequencies(word_freq)\n    fig, ax = plt.subplots(figsize=(14, 7))\n    ax.imshow(wc, interpolation='bilinear'); ax.axis('off')\n    ax.set_title('Q7: Negative Review Keywords During Crisis', fontsize=18, fontweight='bold', color=NAVY, pad=15)\n    plt.tight_layout()\n    plt.savefig(f'{OUTPUT_DIR}Q7a_word_cloud.png', dpi=150, bbox_inches='tight')\n    plt.show()\n    print(\"\u2705 Chart saved: Q7a_word_cloud.png\")\nexcept ImportError:\n    print(\"\u26a0\ufe0f wordcloud not installed. Run: pip install wordcloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHART Q7b: Keyword Bar Chart\nfig, ax = plt.subplots(figsize=(14, 7))\ntop_words = word_freq.most_common(15)\nwords_list = [w[0] for w in top_words][::-1]\ncounts_list = [w[1] for w in top_words][::-1]\n\nfood_words = {'food','quality','stale','cold','taste','bad'}\nsafety_words = {'safety','issue','packaging'}\ndelivery_words = {'late','delivery','delayed'}\n\nbar_colors = []\nfor w in words_list:\n    if w in food_words: bar_colors.append(RED)\n    elif w in safety_words: bar_colors.append(ORANGE)\n    elif w in delivery_words: bar_colors.append(PURPLE)\n    else: bar_colors.append(GRAY)\n\nbars = ax.barh(words_list, counts_list, color=bar_colors, height=0.6, edgecolor='white', zorder=3)\nfor bar, val in zip(bars, counts_list):\n    ax.text(bar.get_width() + 30, bar.get_y() + bar.get_height()/2, f'{val:,}', va='center', fontsize=10, fontweight='bold', color=NAVY)\n\nlegend_elements = [Patch(facecolor=RED, label='Food Quality'), Patch(facecolor=ORANGE, label='Safety/Packaging'),\n                   Patch(facecolor=PURPLE, label='Delivery'), Patch(facecolor=GRAY, label='Other')]\nax.legend(handles=legend_elements, loc='lower right', fontsize=10)\nax.set_title('Q7b: Top 15 Negative Keywords', fontsize=16, fontweight='bold', color=NAVY, pad=15)\nax.set_xlabel('Frequency', fontsize=12, color=GRAY)\nax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\nplt.tight_layout()\nplt.savefig(f'{OUTPUT_DIR}Q7b_keyword_frequency.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"\u2705 Chart saved: Q7b_keyword_frequency.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7 Insight Summary\n\n",
    "**Finding:** Dominant complaints: **food quality** (food, quality, stale, cold), **safety** (safety, issue, packaging), and **delivery** (late).\n\n",
    "- \"food\" and \"quality\" overwhelmingly top \u2014 this is a food trust crisis.\n",
    "- \"safety\" and \"stale\" directly align with the viral food safety incident.\n",
    "- Recovery messaging must center on food safety audits, quality guarantees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Q9: Loyalty Impact \u2014 Churned Loyal Customers\n\n> **Question:** Among customers who placed 5+ orders before the crisis, how many stopped ordering during the crisis? Of those, how many had avg rating above 4.5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\nprint(\"Q9: LOYALTY IMPACT\")\nprint(\"=\" * 70)\n\npre_crisis = fact_orders[fact_orders['phase'] == 'Pre-Crisis']\ncrisis = fact_orders[fact_orders['phase'] == 'Crisis']\n\npre_cust_counts = pre_crisis.groupby('customer_id').size().reset_index(name='pre_orders')\nloyal_customers = pre_cust_counts[pre_cust_counts['pre_orders'] >= 5].copy()\nprint(f\"\\nLoyal Customers (5+ pre-crisis orders): {len(loyal_customers):,}\")\n\ncrisis_customer_ids = set(crisis['customer_id'].unique())\nloyal_customers['churned'] = ~loyal_customers['customer_id'].isin(crisis_customer_ids)\n\nchurned = loyal_customers[loyal_customers['churned']]\nactive = loyal_customers[~loyal_customers['churned']]\nprint(f\"Churned: {len(churned):,} ({len(churned)/len(loyal_customers)*100:.1f}%)\")\nprint(f\"Still Active: {len(active):,}\")\n\n# High-rating churners\nchurned_ratings = fact_ratings[fact_ratings['customer_id'].isin(churned['customer_id'])]\nchurned_avg = churned_ratings.groupby('customer_id')['rating'].mean().reset_index(name='avg_rating')\nhigh_rating_churners = churned_avg[churned_avg['avg_rating'] > 4.5]\n\nprint(f\"\\n\ud83d\udccb KEY METRICS:\")\nprint(f\"   Loyal Customers:            {len(loyal_customers):,}\")\nprint(f\"   Churned During Crisis:      {len(churned):,} ({len(churned)/len(loyal_customers)*100:.1f}%)\")\nprint(f\"   \ud83d\udd34 High-Rating Churners:    {len(high_rating_churners):,} (avg > 4.5)\")\nprint(f\"   \u26a0\ufe0f These were SATISFIED customers who left \u2014 highest recovery potential!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHART Q9: Loyalty Impact\nfig, axes = plt.subplots(1, 3, figsize=(16, 6))\n\n# Left: Churn donut\nax1 = axes[0]\nsizes = [len(churned), len(active)]\nlabels = [f'Churned\\n{len(churned)}', f'Active\\n{len(active)}']\nwedges, texts, autotexts = ax1.pie(sizes, labels=labels, colors=[RED, GREEN], autopct='%1.0f%%',\n    startangle=90, textprops={'fontsize': 11}, pctdistance=0.7, wedgeprops=dict(width=0.5))\nfor a in autotexts: a.set_fontweight('bold')\nax1.set_title('Loyal Customers\\n(5+ orders)', fontsize=14, fontweight='bold', color=NAVY, pad=15)\n\n# Middle: High-rating churners\nax2 = axes[1]\nhigh_ct = len(high_rating_churners)\nlow_ct = len(churned_avg) - high_ct\nno_data = len(churned) - len(churned_avg)\nwedges2, texts2, autotexts2 = ax2.pie([high_ct, low_ct, no_data],\n    labels=[f'Rating>4.5\\n{high_ct}', f'Rating\u22644.5\\n{low_ct}', f'No Rating\\n{no_data}'],\n    colors=[ORANGE, NAVY, GRAY], autopct='%1.0f%%', startangle=90,\n    textprops={'fontsize': 10}, pctdistance=0.7, wedgeprops=dict(width=0.5))\nfor a in autotexts2: a.set_fontweight('bold')\nax2.set_title('Churned Rating\\nBreakdown', fontsize=14, fontweight='bold', color=NAVY, pad=15)\n\n# Right: KPI text\nax3 = axes[2]; ax3.axis('off')\nkpi = f\"KEY FINDINGS\\n\\nLoyal Customers:  {len(loyal_customers)}\\nChurned:          {len(churned)} ({len(churned)/len(loyal_customers)*100:.0f}%)\\nHigh-Rating Lost: {len(high_rating_churners)}\\n\\nThese {len(high_rating_churners)} were HAPPY\\nbefore the crisis.\\n\u2192 Highest recovery potential\\n\u2192 Target for win-back\"\nax3.text(0.1, 0.5, kpi, transform=ax3.transAxes, fontsize=13, verticalalignment='center',\n         fontfamily='monospace', color=NAVY,\n         bbox=dict(boxstyle='round,pad=0.8', facecolor=LIGHT_ORANGE, edgecolor=ORANGE, alpha=0.9))\n\nfig.suptitle('Q9: Loyalty Impact \u2014 Who Did We Lose?', fontsize=16, fontweight='bold', color=NAVY, y=1.02)\nplt.tight_layout()\nplt.savefig(f'{OUTPUT_DIR}Q9_loyalty_impact.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"\u2705 Chart saved: Q9_loyalty_impact.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9 Insight Summary\n\n",
    "**Finding:** Of 58 loyal customers, **49 churned (84.5%)**. **26 had avg rating > 4.5** \u2014 happy customers who left.\n\n",
    "- The crisis hit loyal customers hardest \u2014 84.5% stopped ordering.\n",
    "- 26 high-rating churners = best win-back targets.\n",
    "- Personalized campaigns (cashback, free delivery) should prioritize these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Q10: High-Value Customer Decline Patterns\n\n> **Question:** Which high-value customers (top 5% by total spend) showed the largest drop in order frequency and ratings? What patterns do they share?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\nprint(\"Q10: HIGH-VALUE CUSTOMER DECLINE PATTERNS\")\nprint(\"=\" * 70)\n\npre_spend = pre_crisis.groupby('customer_id')['total_amount'].sum().reset_index(name='pre_total_spend')\nthreshold_95 = pre_spend['pre_total_spend'].quantile(0.95)\ntop5pct = pre_spend[pre_spend['pre_total_spend'] >= threshold_95].copy()\ntop_ids = set(top5pct['customer_id'])\n\nprint(f\"\\nTop 5% Threshold: \u20b9{threshold_95:,.2f}\")\nprint(f\"Top 5% Customers: {len(top5pct):,}\")\n\n# Crisis behavior\npre_freq = pre_crisis[pre_crisis['customer_id'].isin(top_ids)].groupby('customer_id').size().reset_index(name='pre_freq')\ncrisis_freq = crisis[crisis['customer_id'].isin(top_ids)].groupby('customer_id').size().reset_index(name='crisis_freq')\n\ntop_analysis = top5pct.merge(pre_freq, on='customer_id', how='left')\ntop_analysis = top_analysis.merge(crisis_freq, on='customer_id', how='left')\ntop_analysis['crisis_freq'] = top_analysis['crisis_freq'].fillna(0).astype(int)\ntop_analysis['churned'] = top_analysis['crisis_freq'] == 0\n\nchurned_ct = top_analysis['churned'].sum()\nactive_ct = len(top_analysis) - churned_ct\nprint(f\"Top 5% who CHURNED: {churned_ct:,} ({churned_ct/len(top_analysis)*100:.1f}%)\")\nprint(f\"Top 5% still active: {active_ct:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating decline for top 5%\ntop_ratings = fact_ratings[fact_ratings['customer_id'].isin(top_ids)]\ntop_ratings = top_ratings.merge(fact_orders[['order_id', 'phase']], on='order_id', how='left')\npre_avg_r = top_ratings[top_ratings['phase'] == 'Pre-Crisis'].groupby('customer_id')['rating'].mean()\ncrisis_avg_r = top_ratings[top_ratings['phase'] == 'Crisis'].groupby('customer_id')['rating'].mean()\n\nprint(f\"\u2b50 Rating Decline (Top 5%):\")\nprint(f\"   Pre-Crisis Avg: {pre_avg_r.mean():.2f}\")\nprint(f\"   Crisis Avg:     {crisis_avg_r.mean():.2f}\")\nprint(f\"   Drop:           {pre_avg_r.mean() - crisis_avg_r.mean():.2f} stars\")\n\n# Patterns\ntop_orders = fact_orders[fact_orders['customer_id'].isin(top_ids)]\ntop_rest = top_orders.merge(dim_restaurant[['restaurant_id', 'city', 'cuisine_type']], on='restaurant_id', how='left')\ntop_del = top_orders.merge(fact_delivery, on='order_id', how='left')\ntop_del['delay'] = top_del['actual_delivery_time_mins'] - top_del['expected_delivery_time_mins']\n\nprint(f\"\\n\ud83d\udccd Top Cities: {top_rest['city'].value_counts().head(3).to_dict()}\")\nprint(f\"\ud83c\udf7d\ufe0f Top Cuisines: {top_rest['cuisine_type'].value_counts().head(3).to_dict()}\")\nfor phase in ['Pre-Crisis', 'Crisis']:\n    d = top_del[top_del['phase'] == phase]\n    print(f\"\ud83d\ude97 {phase}: Avg Delivery={d['actual_delivery_time_mins'].mean():.1f}min, Breach={((d['delay']>0).mean()*100):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHART Q10: High-Value Customer Overview\nfig, axes = plt.subplots(1, 3, figsize=(18, 6))\n\n# Churn donut\nax1 = axes[0]\nax1.pie([churned_ct, active_ct], labels=[f'Churned\\n{churned_ct:,}', f'Active\\n{active_ct:,}'],\n        colors=[RED, GREEN], autopct='%1.0f%%', startangle=90, textprops={'fontsize': 12},\n        pctdistance=0.7, wedgeprops=dict(width=0.5))\nax1.set_title(f'Top 5% Customers\\n(\u20b9{threshold_95:,.0f}+ spend)', fontsize=14, fontweight='bold', color=NAVY, pad=15)\n\n# City distribution\nax2 = axes[1]\ncity_dist = top_rest['city'].value_counts().head(8)\nax2.barh(city_dist.index[::-1], city_dist.values[::-1], color=NAVY, height=0.6, zorder=3)\nfor i, (c, v) in enumerate(zip(city_dist.index[::-1], city_dist.values[::-1])):\n    ax2.text(v + 20, i, f'{v:,}', va='center', fontsize=10, fontweight='bold', color=NAVY)\nax2.set_title('Orders by City', fontsize=14, fontweight='bold', color=NAVY, pad=10)\nax2.spines['top'].set_visible(False); ax2.spines['right'].set_visible(False)\n\n# Cuisine\nax3 = axes[2]\ncuis_dist = top_rest['cuisine_type'].value_counts().head(8)\npalette = [NAVY, TEAL, ORANGE, SOFT_BLUE, '#E67E22', PURPLE, '#1ABC9C', RED]\nax3.barh(cuis_dist.index[::-1], cuis_dist.values[::-1], color=palette[:len(cuis_dist)][::-1], height=0.6, zorder=3)\nfor i, (c, v) in enumerate(zip(cuis_dist.index[::-1], cuis_dist.values[::-1])):\n    ax3.text(v + 20, i, f'{v:,}', va='center', fontsize=10, fontweight='bold', color=NAVY)\nax3.set_title('Cuisine Preference', fontsize=14, fontweight='bold', color=NAVY, pad=10)\nax3.spines['top'].set_visible(False); ax3.spines['right'].set_visible(False)\n\nfig.suptitle('Q10: High-Value Customer Patterns', fontsize=16, fontweight='bold', color=NAVY, y=1.02)\nplt.tight_layout()\nplt.savefig(f'{OUTPUT_DIR}Q10_highvalue_overview.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"\u2705 Chart saved: Q10_highvalue_overview.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHART Q10b: Rating Shift\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\nax1 = axes[0]\nbars = ax1.bar(['Pre-Crisis', 'Crisis'], [pre_avg_r.mean(), crisis_avg_r.mean()], color=[NAVY, RED], width=0.4, zorder=3)\nfor bar, val in zip(bars, [pre_avg_r.mean(), crisis_avg_r.mean()]):\n    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05,\n             f'{val:.2f} \u2605', ha='center', fontsize=14, fontweight='bold', color=NAVY)\nax1.set_ylim(0, 5.5)\nax1.set_title('Rating Shift (Top 5%)', fontsize=14, fontweight='bold', color=NAVY, pad=10)\nax1.spines['top'].set_visible(False); ax1.spines['right'].set_visible(False)\n\nax2 = axes[1]\npre_d = top_del[top_del['phase']=='Pre-Crisis']\ncrisis_d = top_del[top_del['phase']=='Crisis']\nx = np.arange(2); w = 0.3\nax2.bar(x-w/2, [pre_d['expected_delivery_time_mins'].mean(), crisis_d['expected_delivery_time_mins'].mean()],\n        w, label='Expected', color=TEAL, zorder=3)\nax2.bar(x+w/2, [pre_d['actual_delivery_time_mins'].mean(), crisis_d['actual_delivery_time_mins'].mean()],\n        w, label='Actual', color=RED, zorder=3)\nax2.set_xticks(x); ax2.set_xticklabels(['Pre-Crisis', 'Crisis'])\nax2.set_title('Delivery Time (Top 5%)', fontsize=14, fontweight='bold', color=NAVY, pad=10)\nax2.set_ylabel('Minutes'); ax2.legend(fontsize=10)\nax2.spines['top'].set_visible(False); ax2.spines['right'].set_visible(False)\n\nfig.suptitle('Q10b: High-Value Customer Experience Decline', fontsize=16, fontweight='bold', color=NAVY, y=1.02)\nplt.tight_layout()\nplt.savefig(f'{OUTPUT_DIR}Q10b_highvalue_decline.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"\u2705 Chart saved: Q10b_highvalue_decline.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10 Insight Summary\n\n",
    "**Finding:** Of 4,342 top 5% spenders, **3,648 churned (84%)**. Their rating dropped from 4.51 to 2.51 stars.\n\n",
    "**Shared Patterns:**\n",
    "- Heavily concentrated in **Bengaluru, Mumbai, Delhi** (top 3 cities)\n",
    "- Prefer **North Indian, Biryani, Chinese** cuisines\n",
    "- SLA breach rate jumped from ~56% to ~88% for these customers\n",
    "- Delivery times nearly doubled \u2014 this drove them away\n",
    "- Recovery plan: city-specific campaigns in Bengaluru/Mumbai/Delhi, focusing on delivery guarantees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Export Summary & Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export key tables\ncancel_monthly.to_csv(f'{OUTPUT_DIR}Q4_cancellation_monthly.csv', index=False)\nsla_monthly.to_csv(f'{OUTPUT_DIR}Q5_sla_monthly.csv', index=False)\nmonthly_rating.to_csv(f'{OUTPUT_DIR}Q6_rating_monthly.csv', index=False)\npd.DataFrame(word_freq.most_common(50), columns=['keyword','count']).to_csv(f'{OUTPUT_DIR}Q7_keywords.csv', index=False)\ntop_analysis.to_csv(f'{OUTPUT_DIR}Q10_highvalue_analysis.csv', index=False)\n\n# Summary markdown\nwith open(f'{OUTPUT_DIR}ANSWERS_Q4_Q10.md', 'w', encoding='utf-8') as f:\n    f.write('# QuickBite Express \u2014 Deep Analysis Answers (Q4-Q10)\\n\\n')\n    f.write(f'Generated: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\\n\\n---\\n\\n')\n    f.write(f'## Q4: Cancellation Rate\\n- Pre-Crisis: ~6.1% \u2192 Crisis: ~11.9% (nearly doubled)\\n')\n    f.write(f'- Most affected: Ahmedabad (13.0%), Mumbai (12.4%)\\n\\n')\n    f.write(f'## Q5: Delivery SLA\\n- Actual delivery: 39.5 \u2192 60.1 mins (+52%)\\n- Breach rate: 56% \u2192 88%\\n\\n')\n    f.write(f'## Q6: Ratings\\n- Avg rating: 4.5 \u2192 2.5 (2-star drop)\\n- Sentiment: +0.75 \u2192 -0.25\\n\\n')\n    f.write(f'## Q7: Keywords\\n- Top: food, quality, issue, packaging, safety, stale, late\\n\\n')\n    f.write(f'## Q9: Loyalty\\n- 58 loyal customers \u2192 49 churned (84.5%)\\n- 26 high-rating churners (avg >4.5)\\n\\n')\n    f.write(f'## Q10: High-Value\\n- 4,342 top 5% \u2192 3,648 churned (84%)\\n- Rating: 4.51 \u2192 2.51\\n- Pattern: Bengaluru/Mumbai/Delhi, North Indian/Biryani\\n')\n\nprint(f\"\ud83d\udcc1 All outputs saved to: {OUTPUT_DIR}\")\nfor f in sorted(os.listdir(OUTPUT_DIR)):\n    print(f\"   {f}\")\nprint(\"\\n\ud83c\udfaf Sprint 2 COMPLETE!\")\nprint(\"\ud83d\udccc Next: Sprint 3 \u2192 Dashboard Build + Secondary Research (S1-S5, E1-E3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Sprint 2 Summary \u2014 All Questions Answered\n\n",
    "| Q# | Question | Key Finding |\n",
    "|-----|---------|-------------|\n",
    "| Q4 | Cancellation Rate | **6.1% \u2192 11.9%** (nearly doubled) |\n",
    "| Q5 | Delivery SLA | **39.5 \u2192 60.1 mins**, breach 56% \u2192 88% |\n",
    "| Q6 | Ratings | **4.5 \u2192 2.5 stars** (2-star crash) |\n",
    "| Q7 | Negative Keywords | food, quality, safety, stale, packaging |\n",
    "| Q9 | Loyalty Impact | **49/58 loyal churned** (84.5%), 26 high-rating |\n",
    "| Q10 | High-Value Decline | **3,648/4,342 churned** (84%), Bengaluru/Mumbai/Delhi |\n\n",
    "**Next Sprint:** Dashboard Build + Secondary Research"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}