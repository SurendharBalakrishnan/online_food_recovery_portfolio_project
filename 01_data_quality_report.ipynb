{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuickBite Express - Data Quality Report\n",
    "## Sprint 1, Task 1: Data Loading & Validation\n",
    "\n",
    "**Purpose:** Load all 8 datasets, validate schema, check nulls/duplicates/dtypes, validate star schema relationships, and export a summary report.\n",
    "\n",
    "**Output:** `/output/01_data_quality_report/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded\n",
      "   Data Directory: datasets/\n",
      "   Output Directory: output/01_data_quality_report/\n",
      "   Pre-Crisis: 2025-01-01 to 2025-05-31\n",
      "   Crisis: 2025-06-01 to 2025-09-30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG - Change these paths to reuse for new clients\n",
    "# ============================================================\n",
    "DATA_DIR = \"datasets/\"\n",
    "OUTPUT_DIR = \"output/01_data_quality_report/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "CRISIS_START = \"2025-06-01\"\n",
    "CRISIS_END = \"2025-09-30\"\n",
    "PRE_CRISIS_START = \"2025-01-01\"\n",
    "PRE_CRISIS_END = \"2025-05-31\"\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"   Data Directory: {DATA_DIR}\")\n",
    "print(f\"   Output Directory: {OUTPUT_DIR}\")\n",
    "print(f\"   Pre-Crisis: {PRE_CRISIS_START} to {PRE_CRISIS_END}\")\n",
    "print(f\"   Crisis: {CRISIS_START} to {CRISIS_END}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Load All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading datasets...\n",
      "\n",
      "‚úÖ All 8 datasets loaded successfully!\n",
      "   fact_orders: 149,166 rows x 11 cols\n",
      "   fact_order_items: 342,994 rows x 8 cols\n",
      "   fact_ratings: 68,842 rows x 7 cols\n",
      "   fact_delivery_performance: 149,166 rows x 4 cols\n",
      "   dim_customer: 107,776 rows x 4 cols\n",
      "   dim_restaurant: 19,995 rows x 7 cols\n",
      "   dim_delivery_partner: 15,000 rows x 7 cols\n",
      "   dim_menu_item: 342,671 rows x 6 cols\n"
     ]
    }
   ],
   "source": [
    "print(\"üìÇ Loading datasets...\\n\")\n",
    "\n",
    "fact_orders = pd.read_csv(f\"{DATA_DIR}fact_orders.csv\")\n",
    "fact_order_items = pd.read_csv(f\"{DATA_DIR}fact_order_items.csv\")\n",
    "fact_ratings = pd.read_csv(f\"{DATA_DIR}fact_ratings.csv\")\n",
    "fact_delivery = pd.read_csv(f\"{DATA_DIR}fact_delivery_performance.csv\")\n",
    "dim_customer = pd.read_csv(f\"{DATA_DIR}dim_customer.csv\")\n",
    "dim_restaurant = pd.read_csv(f\"{DATA_DIR}dim_restaurant.csv\")\n",
    "dim_delivery_partner = pd.read_csv(f\"{DATA_DIR}dim_delivery_partner_.csv\")\n",
    "dim_menu_item = pd.read_csv(f\"{DATA_DIR}dim_menu_item.csv\")\n",
    "\n",
    "datasets = {\n",
    "    \"fact_orders\": fact_orders,\n",
    "    \"fact_order_items\": fact_order_items,\n",
    "    \"fact_ratings\": fact_ratings,\n",
    "    \"fact_delivery_performance\": fact_delivery,\n",
    "    \"dim_customer\": dim_customer,\n",
    "    \"dim_restaurant\": dim_restaurant,\n",
    "    \"dim_delivery_partner\": dim_delivery_partner,\n",
    "    \"dim_menu_item\": dim_menu_item,\n",
    "}\n",
    "\n",
    "print(\"‚úÖ All 8 datasets loaded successfully!\")\n",
    "for name, df in datasets.items():\n",
    "    print(f\"   {name}: {len(df):,} rows x {df.shape[1]} cols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TABLE 1: DATASET OVERVIEW\n",
      "======================================================================\n",
      "                    Table    Rows  Columns  Memory (MB)\n",
      "              fact_orders 149,166       11        69.96\n",
      "         fact_order_items 342,994        8        99.77\n",
      "             fact_ratings  68,842        7        24.13\n",
      "fact_delivery_performance 149,166        4        13.66\n",
      "             dim_customer 107,776        4        26.88\n",
      "           dim_restaurant  19,995        7         8.78\n",
      "     dim_delivery_partner  15,000        7         5.53\n",
      "            dim_menu_item 342,671        6       110.07\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TABLE 1: DATASET OVERVIEW\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "overview_data = []\n",
    "for name, df in datasets.items():\n",
    "    overview_data.append({\n",
    "        \"Table\": name,\n",
    "        \"Rows\": f\"{len(df):,}\",\n",
    "        \"Columns\": df.shape[1],\n",
    "        \"Memory (MB)\": round(df.memory_usage(deep=True).sum() / 1024**2, 2),\n",
    "    })\n",
    "\n",
    "overview_df = pd.DataFrame(overview_data)\n",
    "print(overview_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Null Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TABLE 2: NULL VALUE ANALYSIS\n",
      "======================================================================\n",
      "                    Table              Column  Null Count  Null %\n",
      "              fact_orders delivery_partner_id        5635    3.78\n",
      "         fact_order_items                None           0    0.00\n",
      "             fact_ratings            order_id          17    0.02\n",
      "             fact_ratings         customer_id          17    0.02\n",
      "             fact_ratings       restaurant_id          17    0.02\n",
      "             fact_ratings              rating          17    0.02\n",
      "             fact_ratings         review_text          17    0.02\n",
      "             fact_ratings    review_timestamp          17    0.02\n",
      "             fact_ratings     sentiment_score          17    0.02\n",
      "fact_delivery_performance                None           0    0.00\n",
      "             dim_customer                None           0    0.00\n",
      "           dim_restaurant                None           0    0.00\n",
      "     dim_delivery_partner                None           0    0.00\n",
      "            dim_menu_item                None           0    0.00\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TABLE 2: NULL VALUE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "null_data = []\n",
    "for name, df in datasets.items():\n",
    "    null_counts = df.isnull().sum()\n",
    "    null_cols = null_counts[null_counts > 0]\n",
    "    if len(null_cols) > 0:\n",
    "        for col, count in null_cols.items():\n",
    "            null_data.append({\n",
    "                \"Table\": name,\n",
    "                \"Column\": col,\n",
    "                \"Null Count\": count,\n",
    "                \"Null %\": round(count / len(df) * 100, 2),\n",
    "            })\n",
    "    else:\n",
    "        null_data.append({\n",
    "            \"Table\": name,\n",
    "            \"Column\": \"None\",\n",
    "            \"Null Count\": 0,\n",
    "            \"Null %\": 0.0,\n",
    "        })\n",
    "\n",
    "null_df = pd.DataFrame(null_data)\n",
    "print(null_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Duplicate Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TABLE 3: DUPLICATE CHECK\n",
      "======================================================================\n",
      "                    Table         Primary Key  Full Row Duplicates  PK Duplicates            Status\n",
      "              fact_orders            order_id                    0              0           ‚úÖ Clean\n",
      "         fact_order_items  order_id + item_id                    0              0           ‚úÖ Clean\n",
      "             fact_ratings            order_id                   16             16 ‚ö†Ô∏è Has Duplicates\n",
      "fact_delivery_performance            order_id                    0              0           ‚úÖ Clean\n",
      "             dim_customer         customer_id                    0              0           ‚úÖ Clean\n",
      "           dim_restaurant       restaurant_id                    0              0           ‚úÖ Clean\n",
      "     dim_delivery_partner delivery_partner_id                    0              0           ‚úÖ Clean\n",
      "            dim_menu_item        menu_item_id                    0              0           ‚úÖ Clean\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TABLE 3: DUPLICATE CHECK\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "pk_map = {\n",
    "    \"fact_orders\": \"order_id\",\n",
    "    \"fact_order_items\": None,  # composite key (order_id + item_id)\n",
    "    \"fact_ratings\": \"order_id\",\n",
    "    \"fact_delivery_performance\": \"order_id\",\n",
    "    \"dim_customer\": \"customer_id\",\n",
    "    \"dim_restaurant\": \"restaurant_id\",\n",
    "    \"dim_delivery_partner\": \"delivery_partner_id\",\n",
    "    \"dim_menu_item\": \"menu_item_id\",\n",
    "}\n",
    "\n",
    "dup_data = []\n",
    "for name, df in datasets.items():\n",
    "    pk = pk_map[name]\n",
    "    full_dups = df.duplicated().sum()\n",
    "    if pk:\n",
    "        pk_dups = df[pk].duplicated().sum()\n",
    "    else:\n",
    "        # fact_order_items: composite key\n",
    "        pk_dups = df.duplicated(subset=[\"order_id\", \"item_id\"]).sum()\n",
    "        pk = \"order_id + item_id\"\n",
    "    dup_data.append({\n",
    "        \"Table\": name,\n",
    "        \"Primary Key\": pk,\n",
    "        \"Full Row Duplicates\": full_dups,\n",
    "        \"PK Duplicates\": pk_dups,\n",
    "        \"Status\": \"‚úÖ Clean\" if pk_dups == 0 else \"‚ö†Ô∏è Has Duplicates\",\n",
    "    })\n",
    "\n",
    "dup_df = pd.DataFrame(dup_data)\n",
    "print(dup_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Data Type Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TABLE 4: DATA TYPE CHECK\n",
      "======================================================================\n",
      "                    Table                      Column Current Dtype              Sample Value\n",
      "              fact_orders                    order_id        object           ORD202501023439\n",
      "              fact_orders                 customer_id        object                CUST181110\n",
      "              fact_orders               restaurant_id        object                 REST08622\n",
      "              fact_orders         delivery_partner_id        object                   DP05541\n",
      "              fact_orders             order_timestamp        object       2025-01-01 12:00:00\n",
      "              fact_orders             subtotal_amount       float64                    471.62\n",
      "              fact_orders             discount_amount       float64                     35.44\n",
      "              fact_orders                delivery_fee       float64                     30.56\n",
      "              fact_orders                total_amount       float64                    466.74\n",
      "              fact_orders                      is_cod        object                         N\n",
      "              fact_orders                is_cancelled        object                         N\n",
      "         fact_order_items                    order_id        object           ORD202501006518\n",
      "         fact_order_items                     item_id        object                   ITEM001\n",
      "         fact_order_items                menu_item_id        object            MENU12962_3216\n",
      "         fact_order_items               restaurant_id        object                 REST12962\n",
      "         fact_order_items                    quantity         int64                         2\n",
      "         fact_order_items                  unit_price       float64                     48.31\n",
      "         fact_order_items               item_discount       float64                       0.0\n",
      "         fact_order_items                  line_total       float64                     96.62\n",
      "             fact_ratings                    order_id        object           ORD202501023439\n",
      "             fact_ratings                 customer_id        object                CUST181110\n",
      "             fact_ratings               restaurant_id        object                 REST08622\n",
      "             fact_ratings                      rating       float64                       4.5\n",
      "             fact_ratings                 review_text        object       Super fast delivery\n",
      "             fact_ratings            review_timestamp        object          01-01-2025 15:00\n",
      "             fact_ratings             sentiment_score       float64                      0.75\n",
      "fact_delivery_performance                    order_id        object           ORD202501023439\n",
      "fact_delivery_performance   actual_delivery_time_mins         int64                        31\n",
      "fact_delivery_performance expected_delivery_time_mins         int64                        31\n",
      "fact_delivery_performance                 distance_km       float64                       6.4\n",
      "             dim_customer                 customer_id        object                CUST000007\n",
      "             dim_customer                 signup_date        object                21-03-2025\n",
      "             dim_customer                        city        object                      Pune\n",
      "             dim_customer         acquisition_channel        object                   Organic\n",
      "           dim_restaurant               restaurant_id        object                 REST12962\n",
      "           dim_restaurant             restaurant_name        object Flavours of Sweets Palace\n",
      "           dim_restaurant                        city        object                 Bengaluru\n",
      "           dim_restaurant                cuisine_type        object                   Chinese\n",
      "           dim_restaurant                partner_type        object                Restaurant\n",
      "           dim_restaurant           avg_prep_time_min        object                     26-40\n",
      "           dim_restaurant                   is_active        object                         N\n",
      "     dim_delivery_partner         delivery_partner_id        object                   DP09615\n",
      "     dim_delivery_partner                partner_name        object                    Neha E\n",
      "     dim_delivery_partner                        city        object                 Bengaluru\n",
      "     dim_delivery_partner                vehicle_type        object                   Scooter\n",
      "     dim_delivery_partner             employment_type        object                 Full-time\n",
      "     dim_delivery_partner                  avg_rating       float64                      3.77\n",
      "     dim_delivery_partner                   is_active        object                         Y\n",
      "            dim_menu_item                menu_item_id        object            MENU12962_3216\n",
      "            dim_menu_item               restaurant_id        object                 REST12962\n",
      "            dim_menu_item                   item_name        object        Paneer Tikka Pizza\n",
      "            dim_menu_item                    category        object                     Pizza\n",
      "            dim_menu_item                      is_veg        object                         Y\n",
      "            dim_menu_item                       price       float64                    271.05\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TABLE 4: DATA TYPE CHECK\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "dtype_data = []\n",
    "for name, df in datasets.items():\n",
    "    for col in df.columns:\n",
    "        dtype_data.append({\n",
    "            \"Table\": name,\n",
    "            \"Column\": col,\n",
    "            \"Current Dtype\": str(df[col].dtype),\n",
    "            \"Sample Value\": str(df[col].dropna().iloc[0]) if len(df[col].dropna()) > 0 else \"N/A\",\n",
    "        })\n",
    "\n",
    "dtype_df = pd.DataFrame(dtype_data)\n",
    "print(dtype_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Star Schema Relationship Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TABLE 5: STAR SCHEMA RELATIONSHIP VALIDATION\n",
      "======================================================================\n",
      "      Fact Table           FK Column                 Dim Table           PK Column  Fact Unique Keys  Dim Unique Keys  Orphan Keys  Match %           Status\n",
      "     fact_orders         customer_id              dim_customer         customer_id            105180           107776         4930    95.31  ‚ö†Ô∏è 4930 orphans\n",
      "     fact_orders       restaurant_id            dim_restaurant       restaurant_id             19983            19995            0   100.00          ‚úÖ Valid\n",
      "     fact_orders delivery_partner_id      dim_delivery_partner delivery_partner_id             15000            15000            0   100.00          ‚úÖ Valid\n",
      "     fact_orders            order_id fact_delivery_performance            order_id            149166           149166            0   100.00          ‚úÖ Valid\n",
      "     fact_orders            order_id              fact_ratings            order_id            149166            68825        80341    46.14 ‚ö†Ô∏è 80341 orphans\n",
      "fact_order_items            order_id               fact_orders            order_id            154479           149166        16425    89.37 ‚ö†Ô∏è 16425 orphans\n",
      "fact_order_items        menu_item_id             dim_menu_item        menu_item_id            342671           342671            0   100.00          ‚úÖ Valid\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TABLE 5: STAR SCHEMA RELATIONSHIP VALIDATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "relationships = [\n",
    "    (\"fact_orders\", \"customer_id\", \"dim_customer\", \"customer_id\"),\n",
    "    (\"fact_orders\", \"restaurant_id\", \"dim_restaurant\", \"restaurant_id\"),\n",
    "    (\"fact_orders\", \"delivery_partner_id\", \"dim_delivery_partner\", \"delivery_partner_id\"),\n",
    "    (\"fact_orders\", \"order_id\", \"fact_delivery_performance\", \"order_id\"),\n",
    "    (\"fact_orders\", \"order_id\", \"fact_ratings\", \"order_id\"),\n",
    "    (\"fact_order_items\", \"order_id\", \"fact_orders\", \"order_id\"),\n",
    "    (\"fact_order_items\", \"menu_item_id\", \"dim_menu_item\", \"menu_item_id\"),\n",
    "]\n",
    "\n",
    "rel_data = []\n",
    "for fact_table, fact_col, dim_table, dim_col in relationships:\n",
    "    fact_df = datasets[fact_table]\n",
    "    dim_df = datasets[dim_table]\n",
    "    \n",
    "    fact_keys = set(fact_df[fact_col].dropna().unique())\n",
    "    dim_keys = set(dim_df[dim_col].dropna().unique())\n",
    "    \n",
    "    orphan_count = len(fact_keys - dim_keys)\n",
    "    match_pct = round((1 - orphan_count / len(fact_keys)) * 100, 2) if len(fact_keys) > 0 else 100\n",
    "    \n",
    "    rel_data.append({\n",
    "        \"Fact Table\": fact_table,\n",
    "        \"FK Column\": fact_col,\n",
    "        \"Dim Table\": dim_table,\n",
    "        \"PK Column\": dim_col,\n",
    "        \"Fact Unique Keys\": len(fact_keys),\n",
    "        \"Dim Unique Keys\": len(dim_keys),\n",
    "        \"Orphan Keys\": orphan_count,\n",
    "        \"Match %\": match_pct,\n",
    "        \"Status\": \"‚úÖ Valid\" if orphan_count == 0 else f\"‚ö†Ô∏è {orphan_count} orphans\",\n",
    "    })\n",
    "\n",
    "rel_df = pd.DataFrame(rel_data)\n",
    "print(rel_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.1 Investigate Orphan Keys (Deep Dive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ORPHAN KEY INVESTIGATION\n",
      "======================================================================\n",
      "\n",
      "üìå fact_orders.customer_id -> dim_customer.customer_id\n",
      "   Orphan count: 4930\n",
      "   Sample orphan keys (first 5): ['CUST004561', 'CUST063958', 'CUST042900', 'CUST111308', 'CUST043678']\n",
      "   Affected rows in fact_orders: 5,053 / 149,166 (3.39%)\n",
      "   ‚ÑπÔ∏è Customers in dim but NOT in orders: 7,526\n",
      "   (These are registered customers who never ordered - normal)\n",
      "\n",
      "üìå fact_orders.order_id -> fact_ratings.order_id\n",
      "   Orphan count: 80341\n",
      "   Sample orphan keys (first 5): ['ORD202501022298', 'ORD202503015565', 'ORD202505005961', 'ORD202503013874', 'ORD202502012136']\n",
      "   Affected rows in fact_orders: 80,341 / 149,166 (53.86%)\n",
      "   ‚ÑπÔ∏è NOTE: Not all orders have ratings. This is EXPECTED behavior.\n",
      "   Orders with ratings: 68,825 / 149,166 (46.14%)\n",
      "\n",
      "üìå fact_order_items.order_id -> fact_orders.order_id\n",
      "   Orphan count: 16425\n",
      "   Sample orphan keys (first 5): ['ORD202502005010', 'ORD202503016085', 'ORD202501009724', 'ORD202508008426', 'ORD202507002249']\n",
      "   Affected rows in fact_order_items: 36,348 / 342,994 (10.6%)\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç ORPHAN KEY INVESTIGATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check each relationship with orphans\n",
    "for _, row in rel_df[rel_df[\"Orphan Keys\"] > 0].iterrows():\n",
    "    fact_table = row[\"Fact Table\"]\n",
    "    fact_col = row[\"FK Column\"]\n",
    "    dim_table = row[\"Dim Table\"]\n",
    "    dim_col = row[\"PK Column\"]\n",
    "    \n",
    "    fact_df = datasets[fact_table]\n",
    "    dim_df = datasets[dim_table]\n",
    "    \n",
    "    fact_keys = set(fact_df[fact_col].dropna().unique())\n",
    "    dim_keys = set(dim_df[dim_col].dropna().unique())\n",
    "    \n",
    "    orphans = fact_keys - dim_keys\n",
    "    \n",
    "    print(f\"\\nüìå {fact_table}.{fact_col} -> {dim_table}.{dim_col}\")\n",
    "    print(f\"   Orphan count: {len(orphans)}\")\n",
    "    print(f\"   Sample orphan keys (first 5): {list(orphans)[:5]}\")\n",
    "    \n",
    "    # How many ROWS are affected?\n",
    "    affected_rows = fact_df[fact_df[fact_col].isin(orphans)].shape[0]\n",
    "    print(f\"   Affected rows in {fact_table}: {affected_rows:,} / {len(fact_df):,} ({round(affected_rows/len(fact_df)*100, 2)}%)\")\n",
    "    \n",
    "    # Check if it's a 1:1 relationship issue (fact_ratings doesn't have ALL orders - that's expected)\n",
    "    if dim_table == \"fact_ratings\":\n",
    "        print(f\"   ‚ÑπÔ∏è NOTE: Not all orders have ratings. This is EXPECTED behavior.\")\n",
    "        print(f\"   Orders with ratings: {len(dim_keys):,} / {len(fact_keys):,} ({round(len(dim_keys)/len(fact_keys)*100, 2)}%)\")\n",
    "    \n",
    "    # Check dim_customer - some customers may not have placed orders\n",
    "    if dim_table == \"dim_customer\":\n",
    "        reverse_orphans = dim_keys - fact_keys\n",
    "        print(f\"   ‚ÑπÔ∏è Customers in dim but NOT in orders: {len(reverse_orphans):,}\")\n",
    "        print(f\"   (These are registered customers who never ordered - normal)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Key Statistics & Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TABLE 6: KEY FIELD DISTRIBUTIONS\n",
      "======================================================================\n",
      "\n",
      "üìÖ Order Date Range: 2025-01-01 12:00:00 to 2025-09-30 22:59:00\n",
      "\n",
      "üìä Monthly Order Counts:\n",
      "   2025-01: 23,539 orders [Pre-Crisis] ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2025-02: 22,667 orders [Pre-Crisis] ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2025-03: 23,543 orders [Pre-Crisis] ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2025-04: 21,466 orders [Pre-Crisis] ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2025-05: 22,591 orders [Pre-Crisis] ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2025-06:  9,293 orders [    Crisis] ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2025-07:  8,818 orders [    Crisis] ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2025-08:  8,555 orders [    Crisis] ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2025-09:  8,694 orders [    Crisis] ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TABLE 6: KEY FIELD DISTRIBUTIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Orders date range\n",
    "fact_orders[\"order_timestamp\"] = pd.to_datetime(fact_orders[\"order_timestamp\"])\n",
    "print(f\"\\nüìÖ Order Date Range: {fact_orders['order_timestamp'].min()} to {fact_orders['order_timestamp'].max()}\")\n",
    "\n",
    "# Monthly order counts\n",
    "monthly = fact_orders.groupby(fact_orders[\"order_timestamp\"].dt.to_period(\"M\")).size()\n",
    "print(f\"\\nüìä Monthly Order Counts:\")\n",
    "for period, count in monthly.items():\n",
    "    phase = \"Pre-Crisis\" if str(period) <= \"2025-05\" else \"Crisis\"\n",
    "    bar = \"‚ñà\" * int(count / 1000)\n",
    "    print(f\"   {period}: {count:>6,} orders [{phase:>10}] {bar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Cancellation Distribution:\n",
      "   N: 138,054 (92.55%)\n",
      "   Y: 11,112 (7.45%)\n",
      "\n",
      "üí∞ COD Distribution:\n",
      "   N: 102,351 (68.62%)\n",
      "   Y: 46,815 (31.38%)\n"
     ]
    }
   ],
   "source": [
    "# Cancellation check\n",
    "cancel_counts = fact_orders[\"is_cancelled\"].value_counts()\n",
    "print(f\"‚ùå Cancellation Distribution:\")\n",
    "for val, count in cancel_counts.items():\n",
    "    print(f\"   {val}: {count:,} ({round(count/len(fact_orders)*100, 2)}%)\")\n",
    "\n",
    "# COD check\n",
    "cod_counts = fact_orders[\"is_cod\"].value_counts()\n",
    "print(f\"\\nüí∞ COD Distribution:\")\n",
    "for val, count in cod_counts.items():\n",
    "    print(f\"   {val}: {count:,} ({round(count/len(fact_orders)*100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèôÔ∏è Cities: ['Ahmedabad', 'Bengaluru', 'Chennai', 'Delhi', 'Hyderabad', 'Kolkata', 'Mumbai', 'Pune']\n",
      "\n",
      "üçΩÔ∏è Cuisine Types: ['Biryani', 'Chinese', 'Desserts', 'Fast Food', 'Healthy', 'North Indian', 'Pizza', 'South Indian']\n",
      "\n",
      "üè™ Partner Types: ['Cloud Kitchen', 'Restaurant']\n",
      "\n",
      "üöó Vehicle Types: ['Bike', 'Car', 'Cycle', 'Scooter']\n",
      "\n",
      "üì¢ Acquisition Channels: ['Organic', 'Paid', 'Referral', 'Social']\n"
     ]
    }
   ],
   "source": [
    "# Categorical distributions\n",
    "print(f\"üèôÔ∏è Cities: {sorted(dim_customer['city'].unique())}\")\n",
    "print(f\"\\nüçΩÔ∏è Cuisine Types: {sorted(dim_restaurant['cuisine_type'].unique())}\")\n",
    "print(f\"\\nüè™ Partner Types: {sorted(dim_restaurant['partner_type'].unique())}\")\n",
    "print(f\"\\nüöó Vehicle Types: {sorted(dim_delivery_partner['vehicle_type'].unique())}\")\n",
    "print(f\"\\nüì¢ Acquisition Channels: {sorted(dim_customer['acquisition_channel'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚≠ê Rating Range: 1.0 to 5.0\n",
      "üìù Sentiment Score Range: -1.0 to 1.0\n",
      "üìù Reviews Available: 68,825 / 68,842\n"
     ]
    }
   ],
   "source": [
    "# Ratings & sentiment\n",
    "print(f\"‚≠ê Rating Range: {fact_ratings['rating'].min()} to {fact_ratings['rating'].max()}\")\n",
    "print(f\"üìù Sentiment Score Range: {fact_ratings['sentiment_score'].min()} to {fact_ratings['sentiment_score'].max()}\")\n",
    "print(f\"üìù Reviews Available: {fact_ratings['review_text'].notna().sum():,} / {len(fact_ratings):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Numeric Field Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TABLE 7: NUMERIC FIELD STATISTICS (fact_orders)\n",
      "======================================================================\n",
      "       subtotal_amount  discount_amount  delivery_fee  total_amount\n",
      "count        149166.00        149166.00     149166.00     149166.00\n",
      "mean            314.37            18.89         30.07        325.55\n",
      "std             147.35            29.80         11.00        146.79\n",
      "min               0.00             0.00          0.00          0.00\n",
      "25%             234.96             0.00         24.73        249.84\n",
      "50%             309.07             0.00         31.48        321.70\n",
      "75%             396.29            34.69         38.24        406.59\n",
      "max             900.00           222.53         45.00        944.91\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TABLE 7: NUMERIC FIELD STATISTICS (fact_orders)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "numeric_cols = [\"subtotal_amount\", \"discount_amount\", \"delivery_fee\", \"total_amount\"]\n",
    "stats = fact_orders[numeric_cols].describe().round(2)\n",
    "print(stats.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TABLE 8: DELIVERY PERFORMANCE STATISTICS\n",
      "======================================================================\n",
      "       actual_delivery_time_mins  expected_delivery_time_mins  distance_km\n",
      "count                  149166.00                    149166.00    149166.00\n",
      "mean                       44.40                        38.69         4.49\n",
      "std                        12.78                         5.07         2.02\n",
      "min                        25.00                        30.00         1.00\n",
      "25%                        36.00                        35.00         2.70\n",
      "50%                        42.00                        39.00         4.50\n",
      "75%                        50.00                        43.00         6.20\n",
      "max                        90.00                        50.00         8.00\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TABLE 8: DELIVERY PERFORMANCE STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "del_stats = fact_delivery[[\"actual_delivery_time_mins\", \"expected_delivery_time_mins\", \"distance_km\"]].describe().round(2)\n",
    "print(del_stats.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Data Quality Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìã DATA QUALITY SUMMARY\n",
      "======================================================================\n",
      "\n",
      "   Data Completeness:         99.93%\n",
      "   Total Null Values:         5,754\n",
      "   PK Duplicates Found:       16\n",
      "   Total Orphan Keys:         101,696\n",
      "   Expected Orphans (ratings): 80,341 (not all orders get rated)\n",
      "   Unexpected Orphans:        21,355\n",
      "   Tables Validated:          8/8\n",
      "   Relationships Checked:     7/7\n",
      "\n",
      "   üèÜ OVERALL DATA QUALITY SCORE: 93.3%\n",
      "   ‚ö†Ô∏è GO/NO-GO: PROCEED WITH CAUTION - Document known issues\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"üìã DATA QUALITY SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "total_nulls = sum(df.isnull().sum().sum() for df in datasets.values())\n",
    "total_cells = sum(df.shape[0] * df.shape[1] for df in datasets.values())\n",
    "completeness = round((1 - total_nulls / total_cells) * 100, 2)\n",
    "\n",
    "total_pk_dups = sum(row[\"PK Duplicates\"] for _, row in dup_df.iterrows())\n",
    "total_orphans = sum(row[\"Orphan Keys\"] for _, row in rel_df.iterrows())\n",
    "\n",
    "# Adjusted orphan count: exclude fact_orders -> fact_ratings (expected: not all orders have ratings)\n",
    "expected_orphan_row = rel_df[(rel_df[\"Fact Table\"] == \"fact_orders\") & (rel_df[\"Dim Table\"] == \"fact_ratings\")]\n",
    "expected_orphans = expected_orphan_row[\"Orphan Keys\"].values[0] if len(expected_orphan_row) > 0 else 0\n",
    "adjusted_orphans = total_orphans - expected_orphans\n",
    "\n",
    "print(f\"\\n   Data Completeness:         {completeness}%\")\n",
    "print(f\"   Total Null Values:         {total_nulls:,}\")\n",
    "print(f\"   PK Duplicates Found:       {total_pk_dups:,}\")\n",
    "print(f\"   Total Orphan Keys:         {total_orphans:,}\")\n",
    "print(f\"   Expected Orphans (ratings): {expected_orphans:,} (not all orders get rated)\")\n",
    "print(f\"   Unexpected Orphans:        {adjusted_orphans:,}\")\n",
    "print(f\"   Tables Validated:          {len(datasets)}/8\")\n",
    "print(f\"   Relationships Checked:     {len(relationships)}/7\")\n",
    "\n",
    "# Adjusted quality score\n",
    "quality_score = completeness\n",
    "if total_pk_dups > 0:\n",
    "    quality_score -= min(5, total_pk_dups * 0.1)  # small penalty for few dups\n",
    "if adjusted_orphans > 0:\n",
    "    quality_score -= min(5, adjusted_orphans / 1000)  # capped penalty\n",
    "\n",
    "print(f\"\\n   üèÜ OVERALL DATA QUALITY SCORE: {round(quality_score, 1)}%\")\n",
    "if quality_score >= 95:\n",
    "    print(\"   ‚úÖ GO/NO-GO: PROCEED TO ANALYSIS\")\n",
    "elif quality_score >= 85:\n",
    "    print(\"   ‚ö†Ô∏è GO/NO-GO: PROCEED WITH CAUTION - Document known issues\")\n",
    "else:\n",
    "    print(\"   ‚ùå GO/NO-GO: REVIEW ISSUES BEFORE PROCEEDING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Export Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Reports exported to: output/01_data_quality_report/\n",
      "   - 01_dataset_overview.csv\n",
      "   - 02_null_analysis.csv\n",
      "   - 03_duplicate_check.csv\n",
      "   - 04_relationship_validation.csv\n",
      "   - 05_dtype_check.csv\n",
      "   - DATA_QUALITY_REPORT.md\n",
      "\n",
      "‚úÖ Sprint 1, Task 1 COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "# Export to CSV\n",
    "overview_df.to_csv(f\"{OUTPUT_DIR}01_dataset_overview.csv\", index=False)\n",
    "null_df.to_csv(f\"{OUTPUT_DIR}02_null_analysis.csv\", index=False)\n",
    "dup_df.to_csv(f\"{OUTPUT_DIR}03_duplicate_check.csv\", index=False)\n",
    "rel_df.to_csv(f\"{OUTPUT_DIR}04_relationship_validation.csv\", index=False)\n",
    "dtype_df.to_csv(f\"{OUTPUT_DIR}05_dtype_check.csv\", index=False)\n",
    "\n",
    "# Export full summary as markdown (no tabulate dependency)\n",
    "with open(f\"{OUTPUT_DIR}DATA_QUALITY_REPORT.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# QuickBite Express - Data Quality Report\\n\\n\")\n",
    "    f.write(f\"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    f.write(f\"**Data Quality Score:** {round(quality_score, 1)}%\\n\\n\")\n",
    "    f.write(\"---\\n\\n\")\n",
    "    \n",
    "    f.write(\"## Dataset Overview\\n\\n\")\n",
    "    f.write(overview_df.to_csv(index=False))\n",
    "    \n",
    "    f.write(\"\\n## Null Analysis\\n\\n\")\n",
    "    f.write(null_df.to_csv(index=False))\n",
    "    \n",
    "    f.write(\"\\n## Duplicate Check\\n\\n\")\n",
    "    f.write(dup_df.to_csv(index=False))\n",
    "    \n",
    "    f.write(\"\\n## Relationship Validation\\n\\n\")\n",
    "    f.write(rel_df.to_csv(index=False))\n",
    "    \n",
    "    f.write(\"\\n---\\n\")\n",
    "    f.write(f\"\\n**Completeness:** {completeness}%\\n\")\n",
    "    f.write(f\"**PK Duplicates:** {total_pk_dups}\\n\")\n",
    "    f.write(f\"**Unexpected Orphans:** {adjusted_orphans}\\n\")\n",
    "    f.write(f\"\\n**Status:** {'PROCEED TO ANALYSIS' if quality_score >= 85 else 'REVIEW ISSUES'}\\n\")\n",
    "\n",
    "print(f\"üìÅ Reports exported to: {OUTPUT_DIR}\")\n",
    "print(\"   - 01_dataset_overview.csv\")\n",
    "print(\"   - 02_null_analysis.csv\")\n",
    "print(\"   - 03_duplicate_check.csv\")\n",
    "print(\"   - 04_relationship_validation.csv\")\n",
    "print(\"   - 05_dtype_check.csv\")\n",
    "print(\"   - DATA_QUALITY_REPORT.md\")\n",
    "print(\"\\n‚úÖ Sprint 1, Task 1 COMPLETE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary & Next Steps\n",
    "\n",
    "**Key Findings:**\n",
    "- Not all orders have ratings ‚Äî this is expected (fact_ratings is a subset)\n",
    "- Orphan keys from orders->ratings are NOT data quality issues\n",
    "- Check orphan investigation section above for any real issues\n",
    "\n",
    "**Next:** Sprint 1, Task 2 ‚Üí Star Schema Implementation + EDA (Q1, Q2, Q3, Q8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
